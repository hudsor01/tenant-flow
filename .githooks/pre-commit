#!/bin/bash
# Enhanced Pre-commit Hook for TenantFlow
# Optimized for Google Search Console and comprehensive code quality

echo "🚀 TenantFlow Pre-commit Hook - Enhanced Quality & SEO Checks"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
SEO_SCRIPT="$PROJECT_ROOT/scripts/generate-seo-optimized.js"
HOOK_START_TIME=$(date +%s)

# Color codes for output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log_step() {
    local message="$1"
    local type="${2:-info}"
    
    case $type in
        "success") echo -e "${GREEN}✅ $message${NC}" ;;
        "warning") echo -e "${YELLOW}⚠️  $message${NC}" ;;
        "error") echo -e "${RED}❌ $message${NC}" ;;
        "info") echo -e "${BLUE}📝 $message${NC}" ;;
        *) echo "   $message" ;;
    esac
}

# Check if staged files exist
staged_files=$(git diff --cached --name-only)
if [ -z "$staged_files" ]; then
    log_step "No staged files found - skipping checks" "warning"
    exit 0
fi

# 1. PRIORITY: Enhanced SEO Generation
log_step "Checking if SEO files need updating..."
if [ -f "$SEO_SCRIPT" ]; then
    # Only regenerate if source files have changed
    source_changed=false
    for file in $staged_files; do
        if [[ "$file" =~ \.(tsx?|jsx?|json)$ ]] && [[ "$file" =~ (pages|routes|components) ]]; then
            source_changed=true
            break
        fi
    done
    
    if [ "$source_changed" = true ]; then
        log_step "Source files changed - regenerating SEO files..."
        if node "$SEO_SCRIPT"; then
            log_step "SEO files generated successfully" "success"
            
            # Auto-stage SEO files if they were updated
            seo_files=(
                "apps/frontend/public/sitemap.xml"
                "apps/frontend/public/sitemap-states.xml"
                "apps/frontend/public/sitemap-index.xml"
                "apps/frontend/public/robots.txt"
                "apps/frontend/public/structured-data.json"
            )
            
            for seo_file in "${seo_files[@]}"; do
                if [ -f "$seo_file" ] && ! git diff --quiet "$seo_file" 2>/dev/null; then
                    git add "$seo_file"
                    log_step "Staged updated $(basename "$seo_file")" "info"
                fi
            done
        else
            log_step "SEO generation failed - continuing anyway" "warning"
        fi
    else
        log_step "No source changes detected - skipping SEO generation" "info"
    fi
else
    log_step "SEO generation script not found - skipping" "warning"
fi

# 2. Secrets Detection
log_step "Scanning for secrets and sensitive data..."
secrets_found=false

# Check for common secret patterns (excluding TypeScript type definitions)
secret_patterns=(
    "password[[:space:]]*=[[:space:]]*['\"][^'\"]{8,}['\"]"
    "api[_-]?key[[:space:]]*=[[:space:]]*['\"][^'\"]{16,}['\"]"
    "secret[[:space:]]*=[[:space:]]*['\"][^'\"]{16,}['\"]"
    "token[[:space:]]*=[[:space:]]*['\"][^'\"]{16,}['\"]"
    "sk_[a-zA-Z0-9_]{20,}"
    "pk_[a-zA-Z0-9_]{20,}"
    "ghp_[a-zA-Z0-9_]{36,}"
    "gho_[a-zA-Z0-9_]{36,}"
    "ghu_[a-zA-Z0-9_]{36,}"
    "ghs_[a-zA-Z0-9_]{36,}"
    "ghr_[a-zA-Z0-9_]{36,}"
    "-----BEGIN [A-Z ]+-----"
)

# Filter out TypeScript/JavaScript files for type definition exclusions
typescript_files=$(echo "$staged_files" | grep -E '\.(ts|tsx|js|jsx)$' || true)
non_typescript_files=$(echo "$staged_files" | grep -v -E '\.(ts|tsx|js|jsx)$' || true)

for pattern in "${secret_patterns[@]}"; do
    # For TypeScript files, exclude interface/type definitions
    if [ -n "$typescript_files" ]; then
        for file in $typescript_files; do
            if [ -f "$file" ]; then
                # Skip lines that are clearly type definitions
                if grep -E "$pattern" "$file" 2>/dev/null | grep -v -E "^[[:space:]]*(export[[:space:]]+)?(interface|type)[[:space:]]+" | grep -v -E "^[[:space:]]*[a-zA-Z_][a-zA-Z0-9_]*[[:space:]]*:[[:space:]]*" | grep -q .; then
                    secrets_found=true
                    log_step "Potential secret found in $file matching pattern: $pattern" "error"
                fi
            fi
        done
    fi
    
    # For non-TypeScript files, use original logic
    if [ -n "$non_typescript_files" ]; then
        if echo "$non_typescript_files" | xargs grep -l "$pattern" 2>/dev/null; then
            secrets_found=true
            log_step "Potential secret found matching pattern: $pattern" "error"
        fi
    fi
done

if [ "$secrets_found" = true ]; then
    log_step "❌ COMMIT BLOCKED: Secrets detected in staged files!" "error"
    exit 1
fi

# 3. Large File Detection
log_step "Checking for large files..."
large_files_found=false
max_file_size=10485760  # 10MB in bytes

# Get list of files being added or modified (not deleted)
added_files=$(git diff --cached --name-status | grep -E '^[AM]' | cut -f2-)

while IFS= read -r file; do
    # Skip if empty line
    [ -z "$file" ] && continue
    
    # Skip turbo cache and other build artifacts
    if [[ "$file" =~ \.(turbo|next)/|node_modules/|dist/|build/ ]]; then
        continue
    fi
    
    # Only check files that exist on filesystem
    if [ -f "$file" ]; then
        file_size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo 0)
        if [ "$file_size" -gt "$max_file_size" ]; then
            large_files_found=true
            size_mb=$(echo "$file_size" | awk '{printf "%.1f", $1/1024/1024}')
            log_step "Large file detected: $file (${size_mb}MB)" "error"
            log_step "Consider using Git LFS for files larger than 10MB" "info"
        fi
    fi
done <<< "$added_files"

if [ "$large_files_found" = true ]; then
    log_step "❌ COMMIT BLOCKED: Large files detected!" "error"
    log_step "Use 'git reset HEAD <file>' to unstage large files" "info"
    exit 1
fi

# 4. Sensitive File Detection
log_step "Checking for sensitive files..."
sensitive_files_found=false

# Patterns for sensitive files
sensitive_patterns=(
    "\.env$"
    "\.env\."
    "\.pem$"
    "\.key$"
    "\.p12$"
    "\.pfx$"
    "id_rsa"
    "id_dsa"
    "credentials"
    "password"
    "secret"
)

for pattern in "${sensitive_patterns[@]}"; do
    if echo "$staged_files" | grep -E "$pattern" >/dev/null 2>&1; then
        sensitive_files_found=true
        log_step "Sensitive file pattern detected: $pattern" "error"
    fi
done

if [ "$sensitive_files_found" = true ]; then
    log_step "❌ COMMIT BLOCKED: Sensitive files detected!" "error"
    exit 1
fi

# 5. Code Quality Checks (non-blocking)
ts_files=$(echo "$staged_files" | grep -E '\.(ts|tsx)$' || true)
js_files=$(echo "$staged_files" | grep -E '\.(js|jsx)$' || true)

if [ -n "$ts_files" ] || [ -n "$js_files" ]; then
    log_step "Running code quality checks..."
    
    # Change to project root
    cd "$PROJECT_ROOT"
    
    # Quick syntax check only (not full typecheck)
    syntax_errors=false
    for file in $ts_files $js_files; do
        if [ -f "$file" ]; then
            # Basic syntax validation
            if ! node -c "$file" >/dev/null 2>&1; then
                syntax_errors=true
                log_step "Syntax error in $file" "error"
            fi
        fi
    done
    
    if [ "$syntax_errors" = true ]; then
        log_step "❌ COMMIT BLOCKED: Syntax errors found!" "error"
        exit 1
    fi
    
    # Non-blocking quality checks
    log_step "Running lint check (non-blocking)..." "info"
    if command -v npm >/dev/null 2>&1; then
        npm run lint --silent 2>&1 | head -5 || true
        log_step "Run 'npm run lint' to see full lint results" "info"
    fi
fi

# 6. Import Organization Check
log_step "Checking import organization..."
import_issues_found=false

for file in $staged_files; do
    if [[ "$file" =~ \.(ts|tsx|js|jsx)$ ]] && [ -f "$file" ]; then
        # Check for barrel imports (index.ts exports)
        if grep -q "from.*\/index['\"]" "$file" 2>/dev/null; then
            import_issues_found=true
            log_step "Barrel import detected in $file - use direct imports" "warning"
        fi
    fi
done

# 7. Database Safety Check
log_step "Checking for database safety..."
db_files=$(echo "$staged_files" | grep -E '\.(sql|prisma)$' || true)

if [ -n "$db_files" ]; then
    log_step "Database files detected - ensure migrations are reviewed" "warning"
    for file in $db_files; do
        if grep -i "drop\|delete\|truncate" "$file" 2>/dev/null; then
            log_step "Destructive database operation detected in $file" "warning"
        fi
    done
fi

# Performance Summary
end_time=$(date +%s)
duration=$((end_time - HOOK_START_TIME))

log_step "Pre-commit checks completed in ${duration}s" "success"
log_step "🎉 All checks passed! Proceeding with commit..." "success"

exit 0
