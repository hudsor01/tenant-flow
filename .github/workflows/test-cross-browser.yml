name: Cross-Browser Matrix Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
    types: [opened, synchronize, labeled]
  release:
    types: [created, published]
  schedule:
    # Run weekly on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      browsers:
        description: 'Browsers to test (comma-separated: chromium,firefox,webkit)'
        required: false
        default: 'chromium,firefox,webkit'
        type: string
      include_mobile:
        description: 'Include mobile device testing'
        required: false
        default: true
        type: boolean
      test_scope:
        description: 'Test scope'
        required: false
        default: 'critical-flows'
        type: choice
        options:
          - critical-flows
          - full-suite
          - visual-regression
          - accessibility

env:
  NODE_VERSION: '22.x'
  POSTGRES_VERSION: '15'
  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
  TURBO_TEAM: ${{ vars.TURBO_TEAM }}

concurrency:
  group: cross-browser-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  should-run-cross-browser:
    name: Should Run Cross-Browser Tests
    runs-on: ubuntu-latest
    outputs:
      should-run: ${{ steps.decision.outputs.should-run }}
      browsers: ${{ steps.decision.outputs.browsers }}
      mobile-devices: ${{ steps.decision.outputs.mobile-devices }}
      test-scope: ${{ steps.decision.outputs.test-scope }}
    steps:
      - name: Determine test scope
        id: decision
        run: |
          should_run=false
          browsers="chromium,firefox"  # Default lightweight set
          mobile_devices="iPhone 13,Pixel 7"
          test_scope="critical-flows"

          # Always run on main branch, releases, or schedule
          if [[ "${{ github.ref }}" == "refs/heads/main" ]] || \
             [[ "${{ github.event_name }}" == "release" ]] || \
             [[ "${{ github.event_name }}" == "schedule" ]]; then
            should_run=true
            browsers="chromium,firefox,webkit"  # Full browser set
          fi

          # Run on PRs with specific labels
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "${{ contains(github.event.pull_request.labels.*.name, 'cross-browser') }}" == "true" ]] || \
               [[ "${{ contains(github.event.pull_request.labels.*.name, 'frontend') }}" == "true" ]] || \
               [[ "${{ contains(github.event.pull_request.labels.*.name, 'ui') }}" == "true" ]]; then
              should_run=true
            fi
          fi

          # Use manual inputs if provided
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            should_run=true
            browsers="${{ github.event.inputs.browsers }}"
            test_scope="${{ github.event.inputs.test_scope }}"
            
            if [[ "${{ github.event.inputs.include_mobile }}" == "false" ]]; then
              mobile_devices=""
            fi
          fi

          echo "should-run=$should_run" >> $GITHUB_OUTPUT
          echo "browsers=$browsers" >> $GITHUB_OUTPUT
          echo "mobile-devices=$mobile_devices" >> $GITHUB_OUTPUT
          echo "test-scope=$test_scope" >> $GITHUB_OUTPUT

  setup-cross-browser-environment:
    name: Setup Cross-Browser Environment
    runs-on: ubuntu-latest
    needs: should-run-cross-browser
    if: needs.should-run-cross-browser.outputs.should-run == 'true'
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: tenantflow_cross_browser
          POSTGRES_HOST_AUTH_METHOD: trust
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Cache Turbo
        uses: actions/cache@v4
        with:
          path: .turbo
          key: ${{ runner.os }}-turbo-cross-browser-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-turbo-cross-browser-
            ${{ runner.os }}-turbo-

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit --progress=false
          cd apps/backend && npm run generate

      - name: Build applications
        run: |
          npm run build
        env:
          NODE_ENV: production
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tenantflow_cross_browser
          VITE_BACKEND_URL: http://localhost:8000
          VITE_API_BASE_URL: http://localhost:8000/api
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL_TEST || 'https://test.supabase.co' }}
          VITE_SUPABASE_ANON_KEY: ${{ secrets.VITE_SUPABASE_ANON_KEY_TEST || 'test-key' }}
          VITE_STRIPE_PUBLISHABLE_KEY: ${{ secrets.VITE_STRIPE_PUBLISHABLE_KEY_TEST || 'pk_test_123' }}

      - name: Setup test database
        run: |
          cd apps/backend
          
          # Wait for PostgreSQL
          timeout 60 bash -c 'until pg_isready -h localhost -p 5432 -U postgres; do sleep 1; done'
          
          # Setup database
          npx prisma migrate deploy --schema=./prisma/schema.prisma
          npx prisma db push --schema=./prisma/schema.prisma --accept-data-loss
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tenantflow_cross_browser
          NODE_ENV: test

      - name: Seed cross-browser test data
        run: |
          cd apps/backend
          
          if [ -f "../tests/seed-e2e-data.ts" ]; then
            npx tsx ../tests/seed-e2e-data.ts --cross-browser
          fi
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tenantflow_cross_browser
          NODE_ENV: test

      - name: Start services
        run: |
          # Start backend
          cd apps/backend
          npm run start:prod &
          BACKEND_PID=$!
          echo "BACKEND_PID=$BACKEND_PID" >> $GITHUB_ENV
          
          # Start frontend
          cd ../frontend
          npm run preview -- --port 3000 --host &
          FRONTEND_PID=$!
          echo "FRONTEND_PID=$FRONTEND_PID" >> $GITHUB_ENV
          
          # Wait for services
          timeout 120 bash -c 'until curl -f http://localhost:8000/health; do sleep 2; done'
          timeout 60 bash -c 'until curl -f http://localhost:3000; do sleep 2; done'
        env:
          NODE_ENV: production
          PORT: 8000
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tenantflow_cross_browser
          JWT_SECRET: cross-browser-test-secret
          SUPABASE_URL: ${{ secrets.SUPABASE_URL_TEST || 'https://test.supabase.co' }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY_TEST || 'test-key' }}
          STRIPE_SECRET_KEY: ${{ secrets.STRIPE_SECRET_KEY_TEST || 'sk_test_123' }}

      - name: Cache environment state
        uses: actions/cache@v4
        with:
          path: |
            .env.test
            cross-browser-setup.json
          key: ${{ runner.os }}-cross-browser-env-${{ github.sha }}

  browser-compatibility-matrix:
    name: Browser Compatibility Tests
    runs-on: ${{ matrix.os }}
    needs: [should-run-cross-browser, setup-cross-browser-environment]
    if: needs.should-run-cross-browser.outputs.should-run == 'true'
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        include:
          # Desktop browsers on Ubuntu
          - browser: chromium
            os: ubuntu-latest
            name: "Chrome Linux"
            category: desktop
          - browser: firefox
            os: ubuntu-latest
            name: "Firefox Linux"
            category: desktop
          - browser: webkit
            os: ubuntu-latest
            name: "Safari Linux"
            category: desktop
          
          # Desktop browsers on macOS (for better Safari compatibility)
          - browser: webkit
            os: macos-latest
            name: "Safari macOS"
            category: desktop
          - browser: chromium
            os: macos-latest
            name: "Chrome macOS"
            category: desktop
          
          # Windows testing
          - browser: chromium
            os: windows-latest  
            name: "Chrome Windows"
            category: desktop
          - browser: firefox
            os: windows-latest
            name: "Firefox Windows"
            category: desktop

    steps:
      - name: Skip if browser not in list
        run: |
          browsers="${{ needs.should-run-cross-browser.outputs.browsers }}"
          current_browser="${{ matrix.browser }}"
          
          if [[ "$browsers" != *"$current_browser"* ]]; then
            echo "Skipping $current_browser - not in browser list: $browsers"
            exit 0
          fi

      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit --progress=false

      - name: Install Playwright browsers
        run: |
          npx playwright install ${{ matrix.browser }} --with-deps

      - name: Configure test environment
        run: |
          # Create browser-specific configuration
          echo "BROWSER_NAME=${{ matrix.name }}" >> $GITHUB_ENV
          echo "TEST_CATEGORY=${{ matrix.category }}" >> $GITHUB_ENV
          echo "OS_TYPE=${{ matrix.os }}" >> $GITHUB_ENV

      - name: Run browser compatibility tests
        run: |
          test_scope="${{ needs.should-run-cross-browser.outputs.test-scope }}"
          
          # Determine test pattern based on scope
          case "$test_scope" in
            "critical-flows")
              test_pattern="critical|Critical|smoke|Smoke"
              ;;
            "full-suite")
              test_pattern=".*"
              ;;
            "visual-regression")
              test_pattern="visual|Visual|screenshot|Screenshot"
              ;;
            "accessibility")
              test_pattern="a11y|accessibility|Accessibility"
              ;;
            *)
              test_pattern="critical|Critical"
              ;;
          esac
          
          # Run tests with browser-specific configuration
          npx playwright test \
            --project=${{ matrix.browser }} \
            --grep="$test_pattern" \
            --max-failures=5 \
            --timeout=45000 \
            --retries=2 \
            --reporter=list,html,junit \
            --output-dir=test-results-${{ matrix.name }} \
            tests/e2e/
        env:
          PLAYWRIGHT_TEST_BASE_URL: http://localhost:3000
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/tenantflow_cross_browser
          E2E_API_BASE_URL: http://localhost:8000/api
          E2E_TEST_USER_EMAIL: test-user@tenantflow.com
          E2E_TEST_USER_PASSWORD: TestPassword123!
          PLAYWRIGHT_JUNIT_OUTPUT_NAME: results-${{ matrix.name }}.xml
          BROWSER_TEST_MODE: true

      - name: Run accessibility tests
        if: needs.should-run-cross-browser.outputs.test-scope == 'accessibility' || needs.should-run-cross-browser.outputs.test-scope == 'full-suite'
        run: |
          # Install axe-core for accessibility testing
          npm install -g @axe-core/cli
          
          # Create accessibility test
          cat << 'EOF' > accessibility-test.js
          const { chromium, firefox, webkit } = require('playwright');
          const { injectAxe, checkA11y } = require('axe-playwright');
          
          async function runAccessibilityTests() {
            const browsers = {
              chromium: chromium,
              firefox: firefox,
              webkit: webkit
            };
            
            const browser = await browsers['${{ matrix.browser }}'].launch();
            const context = await browser.newContext();
            const page = await context.newPage();
            
            const pages = [
              { name: 'Home', url: 'http://localhost:3000' },
              { name: 'Dashboard', url: 'http://localhost:3000/dashboard' },
              { name: 'Properties', url: 'http://localhost:3000/properties' }
            ];
            
            const results = {};
            
            for (const testPage of pages) {
              try {
                await page.goto(testPage.url, { waitUntil: 'networkidle' });
                await injectAxe(page);
                
                const violations = await checkA11y(page, null, {
                  detailedReport: true,
                  detailedReportOptions: { html: true }
                });
                
                results[testPage.name] = {
                  url: testPage.url,
                  violations: violations.length,
                  details: violations
                };
                
                console.log(`${testPage.name}: ${violations.length} accessibility violations`);
              } catch (error) {
                console.error(`Error testing ${testPage.name}:`, error.message);
                results[testPage.name] = { error: error.message };
              }
            }
            
            await browser.close();
            
            require('fs').writeFileSync(
              'accessibility-results-${{ matrix.name }}.json', 
              JSON.stringify(results, null, 2)
            );
          }
          
          runAccessibilityTests().catch(console.error);
          EOF
          
          # Install additional accessibility testing dependencies
          npm install axe-playwright
          
          node accessibility-test.js || echo "Accessibility tests completed with warnings"

      - name: Run visual regression tests
        if: needs.should-run-cross-browser.outputs.test-scope == 'visual-regression' || needs.should-run-cross-browser.outputs.test-scope == 'full-suite'
        run: |
          # Create visual regression test
          cat << 'EOF' > visual-regression-test.js
          const { test, expect } = require('@playwright/test');
          
          const pages = [
            { name: 'home', path: '/' },
            { name: 'dashboard', path: '/dashboard' },
            { name: 'properties', path: '/properties' }
          ];
          
          for (const page of pages) {
            test(`Visual regression - ${page.name} - ${{ matrix.name }}`, async ({ page: playwrightPage }) => {
              await playwrightPage.goto(`http://localhost:3000${page.path}`);
              await playwrightPage.waitForLoadState('networkidle');
              
              // Take full page screenshot
              await expect(playwrightPage).toHaveScreenshot(`${page.name}-${{ matrix.name }}.png`, {
                fullPage: true,
                threshold: 0.3, // Allow some variance for cross-browser differences
              });
              
              // Take specific component screenshots
              const mainContent = playwrightPage.locator('main');
              if (await mainContent.count() > 0) {
                await expect(mainContent).toHaveScreenshot(`${page.name}-main-${{ matrix.name }}.png`);
              }
            });
          }
          EOF
          
          # Run visual regression tests
          npx playwright test visual-regression-test.js \
            --project=${{ matrix.browser }} \
            --reporter=list \
            --output-dir=visual-test-results-${{ matrix.name }} || echo "Visual tests completed"

      - name: Capture browser-specific metrics
        run: |
          # Create browser performance and compatibility report
          cat << 'EOF' > browser-metrics.js
          const { chromium, firefox, webkit } = require('playwright');
          
          async function gatherBrowserMetrics() {
            const browsers = {
              chromium: chromium,
              firefox: firefox,
              webkit: webkit
            };
            
            const browser = await browsers['${{ matrix.browser }}'].launch();
            const context = await browser.newContext();
            const page = await context.newPage();
            
            const metrics = {
              browser: '${{ matrix.browser }}',
              os: '${{ matrix.os }}',
              timestamp: new Date().toISOString(),
              pages: {}
            };
            
            const testPages = ['/', '/dashboard', '/properties'];
            
            for (const pagePath of testPages) {
              try {
                const startTime = Date.now();
                await page.goto(`http://localhost:3000${pagePath}`, { waitUntil: 'networkidle' });
                const loadTime = Date.now() - startTime;
                
                // Get performance metrics
                const performanceMetrics = await page.evaluate(() => {
                  const navigation = performance.getEntriesByType('navigation')[0];
                  return {
                    domContentLoaded: navigation.domContentLoadedEventEnd - navigation.domContentLoadedEventStart,
                    loadComplete: navigation.loadEventEnd - navigation.loadEventStart,
                    firstPaint: performance.getEntriesByType('paint').find(e => e.name === 'first-paint')?.startTime || 0
                  };
                });
                
                // Check for JavaScript errors
                const jsErrors = [];
                page.on('pageerror', error => jsErrors.push(error.message));
                
                // Check console warnings/errors
                const consoleMessages = [];
                page.on('console', msg => {
                  if (msg.type() === 'error' || msg.type() === 'warning') {
                    consoleMessages.push({ type: msg.type(), text: msg.text() });
                  }
                });
                
                metrics.pages[pagePath] = {
                  loadTime,
                  performanceMetrics,
                  jsErrors: jsErrors.length,
                  consoleIssues: consoleMessages.length
                };
                
                console.log(`${pagePath}: ${loadTime}ms load time`);
              } catch (error) {
                metrics.pages[pagePath] = { error: error.message };
              }
            }
            
            await browser.close();
            
            require('fs').writeFileSync(
              'browser-metrics-${{ matrix.name }}.json',
              JSON.stringify(metrics, null, 2)
            );
          }
          
          gatherBrowserMetrics().catch(console.error);
          EOF
          
          node browser-metrics.js

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cross-browser-results-${{ matrix.name }}
          path: |
            test-results-${{ matrix.name }}/
            results-${{ matrix.name }}.xml
            accessibility-results-${{ matrix.name }}.json
            browser-metrics-${{ matrix.name }}.json
            visual-test-results-${{ matrix.name }}/
          retention-days: 14

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.name }}
          path: playwright-report/
          retention-days: 14

  mobile-device-testing:
    name: Mobile Device Tests
    runs-on: ubuntu-latest
    needs: [should-run-cross-browser, setup-cross-browser-environment]
    if: needs.should-run-cross-browser.outputs.should-run == 'true' && needs.should-run-cross-browser.outputs.mobile-devices != ''
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        device: 
          - "iPhone 13"
          - "iPhone 13 Mini"
          - "iPad Pro"
          - "Pixel 7"
          - "Galaxy S23"

    steps:
      - name: Skip if device not in list
        run: |
          devices="${{ needs.should-run-cross-browser.outputs.mobile-devices }}"
          current_device="${{ matrix.device }}"
          
          if [[ "$devices" != *"$current_device"* ]]; then
            echo "Skipping $current_device - not in device list: $devices"
            exit 0
          fi

      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit --progress=false

      - name: Install Playwright browsers
        run: |
          npx playwright install chromium --with-deps

      - name: Run mobile device tests
        run: |
          # Create mobile-specific test configuration
          cat << EOF > playwright-mobile.config.js
          const { devices } = require('@playwright/test');
          
          module.exports = {
            testDir: './tests/e2e',
            timeout: 45000,
            use: {
              ...devices['${{ matrix.device }}'],
              baseURL: 'http://localhost:3000',
            },
            projects: [
              {
                name: 'mobile-${{ matrix.device }}',
                use: { ...devices['${{ matrix.device }}'] },
              },
            ],
          };
          EOF
          
          # Run mobile tests
          npx playwright test \
            --config playwright-mobile.config.js \
            --grep="mobile|Mobile|responsive|Responsive|touch|Touch" \
            --project=mobile-${{ matrix.device }} \
            --max-failures=3 \
            --timeout=45000 \
            --reporter=list,html,junit \
            --output-dir=mobile-test-results-${{ matrix.device }}
        env:
          PLAYWRIGHT_TEST_BASE_URL: http://localhost:3000
          E2E_API_BASE_URL: http://localhost:8000/api
          MOBILE_TEST_MODE: true
          PLAYWRIGHT_JUNIT_OUTPUT_NAME: mobile-results-${{ matrix.device }}.xml

      - name: Test mobile-specific features  
        run: |
          # Create mobile feature test
          cat << 'EOF' > mobile-features-test.js
          const { chromium, devices } = require('playwright');
          
          async function testMobileFeatures() {
            const browser = await chromium.launch();
            const context = await browser.newContext({
              ...devices['${{ matrix.device }}']
            });
            const page = await context.newPage();
            
            const features = {
              device: '${{ matrix.device }}',
              timestamp: new Date().toISOString(),
              tests: {}
            };
            
            try {
              await page.goto('http://localhost:3000', { waitUntil: 'networkidle' });
              
              // Test touch interactions
              const touchElement = page.locator('button').first();
              if (await touchElement.count() > 0) {
                await touchElement.tap();
                features.tests.touchInteraction = 'PASS';
              }
              
              // Test responsive layout
              const viewport = page.viewportSize();
              features.tests.viewport = {
                width: viewport.width,
                height: viewport.height,
                isMobile: viewport.width < 768
              };
              
              // Test mobile navigation
              const mobileMenu = page.locator('[data-testid="mobile-menu"], .mobile-menu, button[aria-label*="menu"]');
              if (await mobileMenu.count() > 0) {
                features.tests.mobileNavigation = 'AVAILABLE';
              } else {
                features.tests.mobileNavigation = 'NOT_FOUND';
              }
              
              // Test scroll behavior
              await page.evaluate(() => window.scrollTo(0, document.body.scrollHeight));
              await page.waitForTimeout(1000);
              const scrollPosition = await page.evaluate(() => window.pageYOffset);
              features.tests.scrollBehavior = scrollPosition > 0 ? 'PASS' : 'FAIL';
              
            } catch (error) {
              features.tests.error = error.message;
            }
            
            await browser.close();
            
            require('fs').writeFileSync(
              'mobile-features-${{ matrix.device }}.json',
              JSON.stringify(features, null, 2)
            );
            
            console.log('Mobile features test completed for ${{ matrix.device }}');
          }
          
          testMobileFeatures().catch(console.error);
          EOF
          
          node mobile-features-test.js

      - name: Upload mobile test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: mobile-test-results-${{ matrix.device }}
          path: |
            mobile-test-results-${{ matrix.device }}/
            mobile-results-${{ matrix.device }}.xml
            mobile-features-${{ matrix.device }}.json
          retention-days: 10

  cross-browser-analysis:
    name: Cross-Browser Analysis
    runs-on: ubuntu-latest
    needs: [should-run-cross-browser, browser-compatibility-matrix, mobile-device-testing]
    if: always() && needs.should-run-cross-browser.outputs.should-run == 'true'
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: "*-results-*"
          merge-multiple: true

      - name: Analyze cross-browser compatibility
        run: |
          # Create comprehensive cross-browser analysis
          cat << 'EOF' > cross-browser-analysis.js
          const fs = require('fs');
          const path = require('path');
          
          function analyzeCrossBrowserResults() {
            const report = {
              timestamp: new Date().toISOString(),
              summary: {
                total_browsers: 0,
                passed_browsers: 0,
                failed_browsers: 0,
                mobile_devices: 0,
                compatibility_score: 0
              },
              browser_results: {},
              mobile_results: {},
              issues: [],
              recommendations: []
            };
            
            // Analyze browser test results
            const browserFiles = fs.readdirSync('.').filter(f => f.startsWith('results-') && f.endsWith('.xml'));
            
            browserFiles.forEach(file => {
              const browserName = file.replace('results-', '').replace('.xml', '');
              report.summary.total_browsers++;
              
              try {
                const content = fs.readFileSync(file, 'utf8');
                const failures = (content.match(/failures="(\d+)"/)?.[1] || '0');
                const tests = (content.match(/tests="(\d+)"/)?.[1] || '0');
                
                if (parseInt(failures) === 0) {
                  report.summary.passed_browsers++;
                  report.browser_results[browserName] = 'PASS';
                } else {
                  report.browser_results[browserName] = `FAIL (${failures}/${tests})`;
                  report.issues.push(`${browserName}: ${failures} test failures`);
                }
              } catch (error) {
                report.browser_results[browserName] = 'ERROR';
                report.issues.push(`${browserName}: Analysis error - ${error.message}`);
              }
            });
            
            // Analyze mobile test results
            const mobileFiles = fs.readdirSync('.').filter(f => f.startsWith('mobile-results-') && f.endsWith('.xml'));
            
            mobileFiles.forEach(file => {
              const deviceName = file.replace('mobile-results-', '').replace('.xml', '');
              report.summary.mobile_devices++;
              
              try {
                const content = fs.readFileSync(file, 'utf8');
                const failures = (content.match(/failures="(\d+)"/)?.[1] || '0');
                const tests = (content.match(/tests="(\d+)"/)?.[1] || '0');
                
                report.mobile_results[deviceName] = parseInt(failures) === 0 ? 'PASS' : `FAIL (${failures}/${tests})`;
              } catch (error) {
                report.mobile_results[deviceName] = 'ERROR';
              }
            });
            
            // Calculate compatibility score
            const totalTests = report.summary.total_browsers + report.summary.mobile_devices;
            if (totalTests > 0) {
              report.summary.compatibility_score = Math.round(
                (report.summary.passed_browsers / report.summary.total_browsers) * 100
              );
            }
            
            // Generate recommendations
            if (report.summary.compatibility_score < 90) {
              report.recommendations.push('Consider fixing browser-specific issues to improve compatibility');
            }
            
            if (Object.values(report.browser_results).includes('Safari Linux')) {
              report.recommendations.push('Test Safari compatibility on actual macOS devices');
            }
            
            if (report.issues.length > 0) {
              report.recommendations.push('Review and fix failing tests across browsers');
            }
            
            fs.writeFileSync('cross-browser-analysis.json', JSON.stringify(report, null, 2));
            return report;
          }
          
          const report = analyzeCrossBrowserResults();
          console.log('Cross-Browser Analysis:', JSON.stringify(report.summary, null, 2));
          EOF
          
          node cross-browser-analysis.js

      - name: Generate compatibility matrix
        run: |
          # Create visual compatibility matrix
          cat << 'EOF' > compatibility-matrix.js
          const fs = require('fs');
          
          if (fs.existsSync('cross-browser-analysis.json')) {
            const analysis = JSON.parse(fs.readFileSync('cross-browser-analysis.json', 'utf8'));
            
            console.log('\n=== CROSS-BROWSER COMPATIBILITY MATRIX ===\n');
            
            console.log('Desktop Browsers:');
            Object.entries(analysis.browser_results).forEach(([browser, result]) => {
              const status = result === 'PASS' ? 'âœ…' : 'âŒ';
              console.log(`  ${status} ${browser}: ${result}`);
            });
            
            if (Object.keys(analysis.mobile_results).length > 0) {
              console.log('\nMobile Devices:');
              Object.entries(analysis.mobile_results).forEach(([device, result]) => {
                const status = result === 'PASS' ? 'âœ…' : 'âŒ';
                console.log(`  ${status} ${device}: ${result}`);
              });
            }
            
            console.log(`\nCompatibility Score: ${analysis.summary.compatibility_score}%`);
            
            if (analysis.issues.length > 0) {
              console.log('\nIssues Found:');
              analysis.issues.forEach(issue => console.log(`  - ${issue}`));
            }
            
            if (analysis.recommendations.length > 0) {
              console.log('\nRecommendations:');
              analysis.recommendations.forEach(rec => console.log(`  - ${rec}`));
            }
          } else {
            console.log('No cross-browser analysis data found');
          }
          EOF
          
          node compatibility-matrix.js

      - name: Generate test summary
        run: |
          echo "# Cross-Browser Test Results ðŸŒ" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "cross-browser-analysis.json" ]; then
            compatibility_score=$(cat cross-browser-analysis.json | jq -r '.summary.compatibility_score')
            total_browsers=$(cat cross-browser-analysis.json | jq -r '.summary.total_browsers')
            passed_browsers=$(cat cross-browser-analysis.json | jq -r '.summary.passed_browsers')
            mobile_devices=$(cat cross-browser-analysis.json | jq -r '.summary.mobile_devices')
            
            if [[ "$compatibility_score" -ge 90 ]]; then
              echo "âœ… **Compatibility Score**: ${compatibility_score}% (Excellent)" >> $GITHUB_STEP_SUMMARY
            elif [[ "$compatibility_score" -ge 75 ]]; then
              echo "âš ï¸ **Compatibility Score**: ${compatibility_score}% (Good)" >> $GITHUB_STEP_SUMMARY
            else
              echo "âŒ **Compatibility Score**: ${compatibility_score}% (Needs Improvement)" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Test Coverage ðŸ“Š" >> $GITHUB_STEP_SUMMARY
            echo "- **Desktop Browsers**: ${passed_browsers}/${total_browsers} passed" >> $GITHUB_STEP_SUMMARY
            echo "- **Mobile Devices**: ${mobile_devices} tested" >> $GITHUB_STEP_SUMMARY
            echo "- **Test Scope**: ${{ needs.should-run-cross-browser.outputs.test-scope }}" >> $GITHUB_STEP_SUMMARY
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Browser Support ðŸ–¥ï¸" >> $GITHUB_STEP_SUMMARY
            
            # Parse browser results
            cat cross-browser-analysis.json | jq -r '.browser_results | to_entries[] | "- **\(.key)**: \(.value)"' >> $GITHUB_STEP_SUMMARY
            
            if [[ "$mobile_devices" -gt 0 ]]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "## Mobile Support ðŸ“±" >> $GITHUB_STEP_SUMMARY
              cat cross-browser-analysis.json | jq -r '.mobile_results | to_entries[] | "- **\(.key)**: \(.value)"' >> $GITHUB_STEP_SUMMARY
            fi
            
            issues_count=$(cat cross-browser-analysis.json | jq -r '.issues | length')
            if [[ "$issues_count" -gt 0 ]]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "## Issues Found âš ï¸" >> $GITHUB_STEP_SUMMARY
              cat cross-browser-analysis.json | jq -r '.issues[]' | sed 's/^/- /' >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âŒ **Status**: Analysis data not available" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload cross-browser analysis
        uses: actions/upload-artifact@v4
        with:
          name: cross-browser-analysis
          path: |
            cross-browser-analysis.json
          retention-days: 30

  cleanup-cross-browser:
    name: Cleanup Cross-Browser Environment
    runs-on: ubuntu-latest
    needs: [browser-compatibility-matrix, mobile-device-testing, cross-browser-analysis]
    if: always()
    steps:
      - name: Cleanup resources
        run: |
          echo "Cross-browser testing cleanup completed"
          # Clean up any remaining processes or temp files